{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "04eb00ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting google-cloud-language\n",
      "  Downloading google_cloud_language-2.13.3-py2.py3-none-any.whl (143 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.7/143.7 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1 in ./anaconda3/lib/python3.10/site-packages (from google-cloud-language) (2.29.0)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in ./anaconda3/lib/python3.10/site-packages (from google-cloud-language) (4.25.3)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in ./anaconda3/lib/python3.10/site-packages (from google-cloud-language) (1.23.0)\n",
      "Requirement already satisfied: google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1 in ./anaconda3/lib/python3.10/site-packages (from google-cloud-language) (2.19.0)\n",
      "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in ./anaconda3/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-language) (2.28.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in ./anaconda3/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-language) (1.63.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in ./anaconda3/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-language) (1.62.2)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in ./anaconda3/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-language) (1.64.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in ./anaconda3/lib/python3.10/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-language) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in ./anaconda3/lib/python3.10/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-language) (4.9)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in ./anaconda3/lib/python3.10/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-language) (5.3.3)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in ./anaconda3/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-language) (0.4.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in ./anaconda3/lib/python3.10/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-language) (1.26.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./anaconda3/lib/python3.10/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-language) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in ./anaconda3/lib/python3.10/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-language) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./anaconda3/lib/python3.10/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-language) (2022.12.7)\n",
      "Installing collected packages: google-cloud-language\n",
      "Successfully installed google-cloud-language-2.13.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade google-cloud-language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304db2f4",
   "metadata": {},
   "source": [
    "# Part 1/2: Audio file Transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f6070067",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File /Users/pawanbtw/Downloads/meeting_demo.mp3 uploaded to audio/meeting_demo.mp3.\n",
      "Waiting for operation to complete...\n",
      "Operation not completed yet. Waiting for 60 seconds...\n",
      "Operation not completed yet. Waiting for 60 seconds...\n",
      "Operation not completed yet. Waiting for 60 seconds...\n",
      "Operation not completed yet. Waiting for 60 seconds...\n",
      "Operation not completed yet. Waiting for 60 seconds...\n",
      "Operation not completed yet. Waiting for 60 seconds...\n",
      "Operation not completed yet. Waiting for 60 seconds...\n",
      "Transcription:\n",
      "Coreg awesome yeah so I see how long you were wanting to jump into the topic for a remodel. So we'll go ahead and do that yep to Jessica using the release from this table inside of the old 70 show again for migrating existing policies into the new cable so once that's done we can complete before we enable the feature flag would it make sense to also implemented for the pipeline execution policies because then we wouldn't would need to have a baker of migration for that inefficient we are going to get along with migration amazing but it looks like at least behind finger play we should be able to make it till 71 release a t-shirt about the migration because it might take a longer time to complete because we have nothing but my slip okay yeah I'm thinking about self Menace if they have like an enormous projects and groups I'm just thinking how we can you know minutes in a blink to fix black and having a migration because obviously we need to First have immigration finished before we can like folding table or we need to have some kind of fell off a fullback that if there is nothing in the okay sounds great thank you so and how how the fallback work for yourself and you still like it's like either might in my grade sir like the result from policies before back to that table Fatso timeline, timeline standpoint Michelle Estep on the feature flag and 17 won the migration could take longer but we can assume then that by 17 to will what kind of wrap this up which then I'm seeing this as a dependency on extending in improving our policy limits at least rumors are passable policies in skin so the next step from there is then we do performance testing in Sumner I guess could we be doing performance testing and establishing than the like number like the women we are able to to have I guess I'll be able to do that in 17-1 regardless or wait on the migration and so is this could be 72 or 73 like what when do you think we could start doing some testing on lemons what is cool that we have with lots of projects and some groups and we can do and then Chris might be an issue for a CD that already in under the limits Epic but yeah there's if there's more information that we can supply there just be prepared and be planning ahead for that that would be helpful and I'll find The Epicure and then if I recall correctly there is also an epic or 17 to how to enhance like Mr approval policies to eat also allow you to specify components and versions of those components I mean for license approval policies I remember we have stuff that bag I believe perhaps we already have a remodel and in the states that where we can extend that with new capabilities I mean we need to I love this company has to be filtered out and we need to use remodel now I'll do to do that because it was like the men's locker or for any any new feature related to policies that are enhancing approval policies and adding new feature to it because we need to have remodel in place because otherwise we need to go back for a visit to hold them all in migration and all that to from day one that we going to introduce this new feature we need to have remodel working without that we have to stop somewhere and that that starts with line okay that's good to know. I didn't see that as a dependency for the license component filter feature is that so take a look at that in the planning I know it's coming up on our priority list so we can make sure that we die all that in if we need to push it out another Milestone or something all right well I'll see I had some some points are sharing in the planning breakdown or at least some notes on playing breakdown where I'm heading next is I'm working on updating our priorities and Direction page there's a few things I want to add just in terms of like context of like sauerkraut ization we're heading the different policy types that we might imagine working on in the future and then just trying to get a few more of these like specific issues elevated that we've been talking about but they're not on the priority page yet so I'll have more clarity on that soon when I can highlight and I was sharing this with with Alexander as well I know it looks like he's not able to join today Madeline quiroz support merch request settings override for any security policy option and I know he and I both had questions if this would be front and only and a half we don't know off the top of her head so we can go a sink but when we rolled this the settings out it was like my enforcement security policies was that overarching epic we added the ability to override Ranch protection settings and replace a pool settings in the policies but one of those abilities is only available if you choose any merger Quest where to find the policy and the other option is available in any case you do any virtual plaster if you do license can be skinny so we'll make sure the settings are available consistently they definitely should be available for any merger quest for that auction and they are but I think it's it makes sense to have this consistent on on if you select also license getting her security scanning so I think we should be going to flush that out and see I think it's this is it that's a small anticipating this be a small effort and it's just one night pulling in from the backlog are these little just minor issues and things that were working on minor improvements that I want to make sure well reflected in that were discussing some of these we might want to wait on I'm not the milestones and sizing and all that as we go but I thought I would I would note that one and then some of this and like still formulating and I want to make sure this is clear and the direction page update that while we're on the team meeting just where I see us heading just off the top of my head I haven't added all my notes here but I hadn't Note 3 here under a she's flying breakdown we're working now on optimizing schedule is Guinness kyushin so that were able to get better handle when and how we trigger schedule scans and how we do this at scale and I think this is going to be important that we were already working on it but as we address this as we improve on it I do anticipate with the pipeline executionpolicy as well that will want to support schedule an excuse and with custom see I had today we're starting with trigger the trigger auctions only but they're plenty of customers have expressed interest in and also be able to enforce the schedule scans and I know there's a lot more to explore and think about are not so make sure that's reflected somewhere in the priority list as a separate Epic and only pull up my list here and see if there's anything Elsa highlights it will work on breaking down improvements around high industry policy project and I think that will work coming across here so it really breaks down into several different issues or the challenges and so one thing we've had reflected in the priority list is allowing users to view the policy his Street in the policy you I so that will be one step to like avoid having to jump across into the into the other project the security policy project to go through the MRI that could be just like when one Improvement to make it easier to stay in the policy you Wyatt cell but we're working on another another epic around us like one step policy scoping process of how do we make it a little bit easier to understand security policy project links and to handle scoping and understand like your permission to access to be able to manage linking all in one place so then that's something that y'all want to make sure it's better reflected and try to figure out like what order we need to do these things in but that's something I expect to see added here by the way, and I believe next week we could talk about it so we could chill design and this this is how we going to actually scope policies and right now we have this link that you need to link crew for project to security policy project we would like to make it somehow automated and in the policy why editor you will be able to specify scope and then we'll menit like all linking will happen behind scene so this is like a huge change because that effectively you know the biggest problem with linking is that you cannot link and get approval to allow or disallow blinking while we would like to change that now so in the policy Southfield able to specify a project or groups where you would like to enable I'll give them policy and then behind scenes we going to Great older slings but anyway it will happen only when Mr. So this is like I finally got it after many weeks of discussing it I would like to achieve it I finally agree on the plan but this is important aspect that we need to clarify because it's not that easy to to understand that the first Clans yeah I find where they were again but I've got the designs up here and yes actually you'll see that we're trying to psych update I feel like there's not a project in lights group I think this is really the screen that better reflects what we're trying to accomplish is that as you do the policy scoping once you select the option then as the next step you can manage the linking based on your permissions so if you want this policy to be late to you know all projects in these groups you could give him more crane earlier by the policies and look have the context of which Bruce will be affected and so the user that creates the policy it will kind of be based on the permissions and instead of having to what say you have a policy or forcing across the Thousand projects if you have the permissions and all those projects to manage linking then you would be able to see all of those groups for projects and you'd be able to to go in and specify that so this kid at the end of these changes it could simplify it to the point of us for the customer to go in and find who were the roles who are the users that I want to go to create a policy scooter my policy creators or who are my security compliance folks and then give them a certain level of access in all of the groups so they could be at each of the top over it straight to the subgroups and then once they've done that all they have to do is go here to the policy and they can only manage it with us today in if you were to do that if you have 1,000 groups that might be going to a 1,000 teens to ask them to get the link created or similarly you have to feel like have access in my 1000 groups and go in and click the button 1000 times or set up some kind of API calls from the others it's a lot of legwork to manage its scale and dumb and that this is going to be a still accept that one proof just kind of the management aspect it's go see if that's that's when one piece of this puzzle and then and then there's the other work that were doing it or it's boring around avoiding having to jump across projects so you're creating at the editor editor be when they have to go into the Coliseum on the policy and was in a different project. So there are a couple layers of those that were identifying and I think we need to sort out a little bit of The Ordering of the work and we're doing some user validation on this as well so we can see if there in each week's there are improvements that come from the feedback there I bet most of this is just giving given a team here a little bit of a heads up in a preview into what and what we're seeing coming down the pipe pink related to we've been talked about security policies by a group of men would have took grouping ability like when you're doing the scoping do not step short short preview into us what's coming and then I'm going to keep working the direction page update and and we can cover more next time as well thanks and one questions I believe I asked this any way related to selection of latest or defaults template I saw that you had its release post item do it just a question are we going to a DUI as well or only like for now on the Yama mode and we'll just pay to customer accounts used to just use it then in the album. Yeah good question yeah I wanted to make sure that was reflected as well and that was I think that's one that's not there yet so I'm choose I think God to answer your question we can start with the yamo interasian but maybe we can clarify that in the stove boobs the issue or if you want to break it down and go on your lower and create an issue that says this is free animal and one is for you I and then we can work on you I enhancement before closing the Epic maybe that would be a better route to get what do you think Allen ideally I would like to release it like thoroughly with you or both of you lying and I can. It's fairly simple drop down somewhere or like selection at its can I assist you'll have like visual on presentation. So what what I wants to have because Danny fist fight in the Alamo don't leave then the policy uy editor will be disabled for you right I believe that for this relatively small yeah I got that designs for able to release it any animal as an iteration more quickly than that it it makes it feasible for customers to pick it up and we do get this question pretty regularly and we've been trying to keep the power to station on Pipeline station policy site because that will satisfy the need as well. damned if you do if you got any more up that we could release its its value did the customer like they'd be able to do it so I think it's a matter of if it from the yard perspective if we can also have that in this Milestone you have that I'm not opposed to that let's try it and see if not full on the other least I am I mean really only have drill this item for Yamamoto on me yeah maybe we can break it down into why I like having you is you if we don't have yet have it and it we can check in with the archer in Alexander and see if they have capacity question the other questions or comments on anything we've been discussing from the team not a single one no questions. I'm thinking we going to have fun like a few minutes bowlerama and pipelines can policy is there any topic that we should prepare like something we need to discuss with Fabio working or for now there's like nothing and they're just moving slow due to have like something that will be merged also I first the one that is at 8:30 is just internal while it's all internal but like this will be just with Martin and and you and I are two turkeys around but the one with with the verify is tomorrow okay that was going to have to have this regular sink to see you there's anything from a broader perspective to get clarified where he opened it up and questioned so they limit the policy limits the topic we've been circling around a bit so we can verify where we are there anything else Martin that would be helpful to discuss with is the broader team I don't think at this point we are still stuck on the first week of the first approval just like an hour ago and now it's on Fabio to do to maintain a review and I also asked you to review it from the security places in perspective so once we have pizza we can work on the floor mops should we meet in few minutes then or it's all clarified for now and we can meet like a in a week I have one point and I would like to talk about just to like clear it up and so yeah I would prefer to have a meeting all right I'll try to join us open questions or the sections from the broader team everything going smoothly otherwise the blockers no hiccups no product questions life is good thumbs UPS life is good all right you have a place yet lined up no I hear that awesome well I guess with that we can adjourn and see a few more minutes Martin than Allen wherever you're going to be Alan will see see where you Lacey\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from google.cloud import storage, speech\n",
    "from google.protobuf.json_format import MessageToJson\n",
    "import time\n",
    "\n",
    "# Set up authentication\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"/Users/pawanbtw/Downloads/sound-works-425306-f1-506b00b9120f.json\"\n",
    "\n",
    "def upload_to_gcs(bucket_name, source_file_name, destination_blob_name):\n",
    "    \"\"\"Uploads a file to the Google Cloud Storage bucket.\"\"\"\n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "    blob = bucket.blob(destination_blob_name)\n",
    "\n",
    "    blob.upload_from_filename(source_file_name)\n",
    "\n",
    "    print(f\"File {source_file_name} uploaded to {destination_blob_name}.\")\n",
    "\n",
    "def transcribe_audio(gcs_uri):\n",
    "    \"\"\"Transcribes the audio file specified by the GCS URI.\"\"\"\n",
    "    client = speech.SpeechClient()\n",
    "\n",
    "    audio = speech.RecognitionAudio(uri=gcs_uri)\n",
    "    config = speech.RecognitionConfig(\n",
    "        encoding=speech.RecognitionConfig.AudioEncoding.MP3,  # Adjust encoding if necessary\n",
    "        sample_rate_hertz=44100,  # Adjust sample rate if necessary\n",
    "        language_code='en-US'\n",
    "    )\n",
    "\n",
    "    operation = client.long_running_recognize(config=config, audio=audio)\n",
    "    print('Waiting for operation to complete...')\n",
    "    \n",
    "    # Polling mechanism\n",
    "    while not operation.done():\n",
    "        print('Operation not completed yet. Waiting for 60 seconds...')\n",
    "        time.sleep(60)\n",
    "    \n",
    "    response = operation.result(timeout=3600)  # 1-hour timeout\n",
    "\n",
    "    transcript = ''.join([result.alternatives[0].transcript for result in response.results])\n",
    "    return transcript\n",
    "\n",
    "# Replace with your bucket name, local file path, and desired GCS file name\n",
    "bucket_name = \"senti-bucket22\"\n",
    "source_file_name = \"/Users/pawanbtw/Downloads/meeting_demo.mp3\"\n",
    "# Replace with your desired GCS file name\n",
    "destination_blob_name = \"audio/meeting_demo.mp3\"\n",
    "\n",
    "# Upload the file to GCS\n",
    "upload_to_gcs(bucket_name, source_file_name, destination_blob_name)\n",
    "\n",
    "# Construct the GCS URI\n",
    "gcs_uri = f\"gs://{bucket_name}/{destination_blob_name}\"\n",
    "\n",
    "# Transcribe the audio file from GCS\n",
    "transcribed_text = transcribe_audio(gcs_uri)\n",
    "print(\"Transcription:\")\n",
    "print(transcribed_text)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b551da",
   "metadata": {},
   "source": [
    "# # Part 2/2: Teams_meeting_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bea223fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment: neutral\n",
      "Sentiment Score: -0.10000000149011612\n",
      "Sentiment Magnitude: 6.400000095367432\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import language_v1\n",
    "\n",
    "def analyze_sentiment(text_content):\n",
    "    \"\"\"Analyzes the sentiment of the text content.\"\"\"\n",
    "    client = language_v1.LanguageServiceClient()\n",
    "\n",
    "    document = language_v1.Document(content=text_content, type_=language_v1.Document.Type.PLAIN_TEXT)\n",
    "    response = client.analyze_sentiment(request={'document': document})\n",
    "\n",
    "    # Get overall sentiment score\n",
    "    sentiment = response.document_sentiment\n",
    "    sentiment_score = sentiment.score\n",
    "    sentiment_magnitude = sentiment.magnitude\n",
    "\n",
    "    return sentiment_score, sentiment_magnitude\n",
    "\n",
    "# Perform sentiment analysis on the transcription\n",
    "sentiment_score, sentiment_magnitude = analyze_sentiment(transcribed_text)\n",
    "\n",
    "# Determine sentiment label based on sentiment score\n",
    "if sentiment_score > 0.2:\n",
    "    sentiment_label = 'positive'\n",
    "elif sentiment_score < -0.2:\n",
    "    sentiment_label = 'negative'\n",
    "else:\n",
    "    sentiment_label = 'neutral'\n",
    "\n",
    "print(f\"Sentiment: {sentiment_label}\")\n",
    "print(f\"Sentiment Score: {sentiment_score}\")\n",
    "print(f\"Sentiment Magnitude: {sentiment_magnitude}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adbb099d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
